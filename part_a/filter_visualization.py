import argparse
from cgi import print_directory
from re import S
from preprocess import generate_batch_train_val
from preprocess import generate_batch_test
from cnn import *
import tensorflow as tf 
import wandb
import numpy as np
import matplotlib.pyplot as plt
from keras import backend as K

#Define the Command Line Arguments
parser = argparse.ArgumentParser(description='Set the directory paths, hyperparameters of the model.')
parser.add_argument('--test_path', type=str, default='inaturalist_12K/val/', help='Path of the test data directory')
parser.add_argument('--batch_size', type=int, default=16, help='Batch size')
parser.add_argument('--image_size', type=int, nargs='+', help='Image size, 2d, (height, width)', required=True)
parser.add_argument('--num_conv_layers', type=int, default=5, help='Number of Convolution Pool Blocks')
parser.add_argument('--best_model_path', type=str, default="wandb", help='Path to best model, default:get from wandb sweep')

#Parse the arguments
args = parser.parse_args()
test_path = args.test_path
batch_size = args.batch_size
image_size = args.image_size
num_conv_layers = args.num_conv_layers
best_model_path = args.best_model_path

#Generate training, validation and test batches.

test_data = generate_batch_test(test_path, batch_size = batch_size, image_size = tuple(image_size))
#Gets the list of class labels.
class_labels = list(test_data.class_indices.keys())

print(class_labels)

#As, our input has 3 channels RGB, our input_shape would have (height, width, channels = 3)
input_shape= image_size
input_shape.append(3)
cnn = CNN(tuple(input_shape))

#Download best weights from wandb 
if best_model_path == 'wandb':
    project_name = '' #Add project name here
    entity = '' #Add username here
    wandb.init(project=project_name, entity=entity)
    api = wandb.Api()
    sweep = api.sweep("") #Add sweep url here : Entity_name/Project_name/sweep_id
    #Sort the runs is descending order of val_accuracy
    runs = sorted(sweep.runs, key=lambda run: run.summary.get("val_accuracy", 0), reverse=True)
    #Pick the top ranked run.
    runs[0].file("model-best.h5").download(replace=True)
    best_model_path = 'model-best.h5'

#Load the model weights from the path
cnn.model = keras.models.load_model(best_model_path)

#Displays the Model summary.
print(cnn.model.summary())

#Evaluates the performance of the model on the test set.
cnn.test(test_data)

#Create a 10x3 grid to visualize 30 images from test set.
fig,ax = plt.subplots(10,3,sharex='col',sharey='row',figsize=(15,45))
fig.text(0.5, 0.04, 'True Label', ha='center', fontsize=18)
fig.text(0.04, 0.5, 'Pred Label', va='center', rotation='vertical', fontsize=18)
plt.legend()
for i in range(10):
    image, true_label = test_data.next()
    pred = cnn.model.predict(image)
    for j in range(3):
        true = class_labels[np.argmax(true_label[j,:])]
        pred_label = class_labels[np.argmax(pred[j,:])]
        ax[i,j].set_xlabel(true, fontsize=18)
        ax[i,j].set_ylabel(pred_label, rotation=90, fontsize=18)
        ax[i,j].imshow(image[j,:])

wandb.log({"Few samples from test data": plt})


#Visualization of Image feature maps extracted by each Filter for a randomly drawn test image  :-

first_conv_layer_index = 0

layers = cnn.model.layers

#Find the index of the first conv layer
for i in range(0, len(layers)):
    if "conv" in layers[i].name:
        first_conv_layer_index = i
        break

#As we have 32 filters, we will visualize them using a 4x8 grid
num_rows, num_col = 4, 8

#We build a Keras function that will return the output of the first Conv Layer
layer_one_output = K.function([cnn.model.layers[first_conv_layer_index].input],
                                  [cnn.model.layers[first_conv_layer_index].output])

#Load the next batch of images
image, true_label = test_data.next()

#Pick the first image of the randomly shuffled batch and pass it as input to get the feature map generated by Conv 1
layer_output = layer_one_output(image[0:1,:])[0]

fig,ax = plt.subplots(num_rows, num_col, figsize=(8,8))
plt.tick_params(axis='x',which='both',bottom=False,top=False)

image_plot  = image[0:1,:][0]

for i in range(num_rows):
    for j in range(num_col):
        #Display each filter as a matrix.
        ax[i,j].matshow(layer_output[0,:,:,i*num_col+j])
        #Remove ticks from display.
        ax[i,j].tick_params(axis='both',which='both',bottom=False,top=False,left=False,labelbottom=False,labelleft=False,labeltop=False)

fig.tight_layout()

#Log the original input image and the plot of feature maps extracted by each filter. 
original_image = wandb.Image(image_plot, caption="Original Image")

wandb.log({"filter_visualization_test_image": plt, "original_image": original_image})

plt.show()

plt.imshow(image_plot)        